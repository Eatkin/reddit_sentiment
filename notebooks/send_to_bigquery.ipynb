{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try and send some data to bigquery to check schemas and whatnot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set environment variable\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/home/ed/code/Eatkin/gcp/reddit-sentiment-400608-24bc7c65b16e.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df = pd.read_csv('../reddit_data/reddit_comments_2023-10-03.csv', index_col=0)\n",
    "posts_df = pd.read_csv('../reddit_data/reddit_posts_2023-10-03.csv', index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a date column to the dataframe\n",
    "comments_df['date'] = datetime.now().strftime('%Y-%m-%d')\n",
    "posts_df['date'] = datetime.now().strftime('%Y-%m-%d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = \"reddit-sentiment-400608\"\n",
    "dataset_id = \"wallstreetbets\"\n",
    "table_id = \"reddit_comments\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish connection\n",
    "client = bigquery.Client(project=project_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up schema\n",
    "comments_schema = [\n",
    "    bigquery.SchemaField(\"date\", \"DATE\"),\n",
    "    bigquery.SchemaField(\"text\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"score\", \"INTEGER\"),\n",
    "    bigquery.SchemaField(\"level\", \"INTEGER\"),\n",
    "    bigquery.SchemaField(\"post\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"url\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"sentiment\", \"FLOAT\"),\n",
    "    bigquery.SchemaField(\"joy\", \"FLOAT\"),\n",
    "    bigquery.SchemaField(\"optimism\", \"FLOAT\"),\n",
    "    bigquery.SchemaField(\"anger\", \"FLOAT\"),\n",
    "    bigquery.SchemaField(\"sadness\", \"FLOAT\"),\n",
    "]\n",
    "\n",
    "posts_schema = [\n",
    "    bigquery.SchemaField(\"date\", \"DATE\"),\n",
    "    bigquery.SchemaField(\"ids\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"titles\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"scores\", \"INTEGER\"),\n",
    "    bigquery.SchemaField(\"controversiality\", \"FLOAT\"),\n",
    "    bigquery.SchemaField(\"bodies\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"original\", \"BOOLEAN\"),\n",
    "    bigquery.SchemaField(\"num_comments\", \"INTEGER\"),\n",
    "    bigquery.SchemaField(\"url\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"sentiment\", \"FLOAT\"),\n",
    "    bigquery.SchemaField(\"joy\", \"FLOAT\"),\n",
    "    bigquery.SchemaField(\"optimism\", \"FLOAT\"),\n",
    "    bigquery.SchemaField(\"anger\", \"FLOAT\"),\n",
    "    bigquery.SchemaField(\"sadness\", \"FLOAT\"),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up job configs\n",
    "comments_job_config = bigquery.LoadJobConfig(\n",
    "    schema=comments_schema,\n",
    "    write_disposition=bigquery.WriteDisposition.WRITE_APPEND,\n",
    ")\n",
    "posts_job_config = bigquery.LoadJobConfig(\n",
    "    schema=posts_schema,\n",
    "    write_disposition=bigquery.WriteDisposition.WRITE_APPEND,\n",
    ")\n",
    "\n",
    "# Bigquery requires dataframe to be in a list so convert to records format\n",
    "comments_records = comments_df.to_dict(orient=\"records\")\n",
    "posts_records = posts_df.to_dict(orient=\"records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pushing comments to Bigquery\n",
      "Pushing posts to Bigquery\n"
     ]
    },
    {
     "ename": "BadRequest",
     "evalue": "400 Error while reading data, error message: JSON table encountered too many errors, giving up. Rows: 1; errors: 1. Please look into the errors[] collection for more details.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequest\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/ed/code/VoeP/reddit_sentiment/notebooks/send_to_bigquery.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/ed/code/VoeP/reddit_sentiment/notebooks/send_to_bigquery.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m table_id \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mreddit_posts\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/ed/code/VoeP/reddit_sentiment/notebooks/send_to_bigquery.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mPushing posts to Bigquery\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/ed/code/VoeP/reddit_sentiment/notebooks/send_to_bigquery.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m client\u001b[39m.\u001b[39;49mload_table_from_json(\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/ed/code/VoeP/reddit_sentiment/notebooks/send_to_bigquery.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     posts_records, \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mproject_id\u001b[39m}\u001b[39;49;00m\u001b[39m.\u001b[39;49m\u001b[39m{\u001b[39;49;00mdataset_id\u001b[39m}\u001b[39;49;00m\u001b[39m.\u001b[39;49m\u001b[39m{\u001b[39;49;00mtable_id\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m, job_config\u001b[39m=\u001b[39;49mposts_job_config\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/ed/code/VoeP/reddit_sentiment/notebooks/send_to_bigquery.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m )\u001b[39m.\u001b[39;49mresult()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/project_name/lib/python3.10/site-packages/google/cloud/bigquery/job/base.py:922\u001b[0m, in \u001b[0;36m_AsyncJob.result\u001b[0;34m(self, retry, timeout)\u001b[0m\n\u001b[1;32m    919\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_begin(retry\u001b[39m=\u001b[39mretry, timeout\u001b[39m=\u001b[39mtimeout)\n\u001b[1;32m    921\u001b[0m kwargs \u001b[39m=\u001b[39m {} \u001b[39mif\u001b[39;00m retry \u001b[39mis\u001b[39;00m DEFAULT_RETRY \u001b[39melse\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mretry\u001b[39m\u001b[39m\"\u001b[39m: retry}\n\u001b[0;32m--> 922\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(_AsyncJob, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/project_name/lib/python3.10/site-packages/google/api_core/future/polling.py:261\u001b[0m, in \u001b[0;36mPollingFuture.result\u001b[0;34m(self, timeout, retry, polling)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_blocking_poll(timeout\u001b[39m=\u001b[39mtimeout, retry\u001b[39m=\u001b[39mretry, polling\u001b[39m=\u001b[39mpolling)\n\u001b[1;32m    258\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    259\u001b[0m     \u001b[39m# pylint: disable=raising-bad-type\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39m# Pylint doesn't recognize that this is valid in this case.\u001b[39;00m\n\u001b[0;32m--> 261\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    263\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\n",
      "\u001b[0;31mBadRequest\u001b[0m: 400 Error while reading data, error message: JSON table encountered too many errors, giving up. Rows: 1; errors: 1. Please look into the errors[] collection for more details."
     ]
    }
   ],
   "source": [
    "# Let's try and push it\n",
    "print(\"Pushing comments to Bigquery\")\n",
    "client.load_table_from_json(\n",
    "    comments_records, f\"{project_id}.{dataset_id}.{table_id}\", job_config=comments_job_config\n",
    ").result()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required because of NaNs\n",
    "for record in posts_records:\n",
    "    if type(record['bodies']) == float:\n",
    "        record['bodies'] = ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pushing posts to Bigquery\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LoadJob<project=reddit-sentiment-400608, location=US, id=b021f8f5-0216-4ba0-89ef-7a0ba1788008>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Switch table id to posts\n",
    "table_id = \"reddit_posts\"\n",
    "\n",
    "print(\"Pushing posts to Bigquery\")\n",
    "client.load_table_from_json(\n",
    "    posts_records, f\"{project_id}.{dataset_id}.{table_id}\", job_config=posts_job_config\n",
    ").result()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_name",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
